{"version":3,"sources":["webpack://millan.[name]/webpack/universalModuleDefinition","webpack://millan.[name]/webpack/bootstrap","webpack://millan.[name]/./src/helpers/cst.ts","webpack://millan.[name]/./src/sparql/W3SpecSparqlParser.ts","webpack://millan.[name]/./src/srs/SrsParser.ts","webpack://millan.[name]/./src/srs/customErrors.ts","webpack://millan.[name]/./src/srs/index.ts","webpack://millan.[name]/./src/srs/tokens.ts","webpack://millan.[name]/./src/srs/visitor.ts","webpack://millan.[name]/./src/turtle/defaultNamespaces.ts"],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC;AACvC,CAAC;AACD,O;ACVA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,gBAAQ,oBAAoB;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,yBAAiB,4BAA4B;AAC7C;AACA;AACA,0BAAkB,2BAA2B;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,kDAA0C,gCAAgC;AAC1E;AACA;;AAEA;AACA;AACA;AACA,gEAAwD,kBAAkB;AAC1E;AACA,yDAAiD,cAAc;AAC/D;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAyC,iCAAiC;AAC1E,wHAAgH,mBAAmB,EAAE;AACrI;AACA;;AAEA;AACA;AACA;AACA,mCAA2B,0BAA0B,EAAE;AACvD,yCAAiC,eAAe;AAChD;AACA;AACA;;AAEA;AACA,8DAAsD,+DAA+D;;AAErH;AACA;;AAEA;AACA;AACA;AACA;AACA,wBAAgB,uBAAuB;AACvC;;;AAGA;AACA;AACA;AACA;;;;;;;;;;;;;ACtJA;AAAA;AAAA;AAAA;AAAA,gBAAgB,SAAI,IAAI,SAAI;AAC5B;AACA,gDAAgD,OAAO;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B,oCAAoC;AACpC;AACA;AACA,CAAC;AACD;AACA,yBAAyB,4BAA4B,aAAa,EAAE;AACpE,iCAAiC,oBAAoB;AACrD;AACA;AACA,8CAA8C;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,8BAA8B;AACrE,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;;;;;;;;;;;;;AChEA;AAAA;AAAA;AAAA;AAAA;AAAA,iBAAiB,SAAI,IAAI,SAAI;AAC7B;AACA;AACA,cAAc,gBAAgB,sCAAsC,iBAAiB,EAAE;AACvF,6BAA6B,uDAAuD;AACpF;AACA;AACA;AACA;AACA,uBAAuB,sBAAsB;AAC7C;AACA;AACA,CAAC;AACD,iBAAiB,mBAAO,CAAC,wCAAU;AACmB;AAClB;AACpC;AACA;AACA;AACA;AACA,QAAQ,iDAAM;AACd;AACA;AACA;AACA,CAAC,CAAC,kEAAgB;AACY;;;;;;;;;;;;;ACzB9B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,iBAAiB,SAAI,IAAI,SAAI;AAC7B;AACA;AACA,cAAc,gBAAgB,sCAAsC,iBAAiB,EAAE;AACvF,6BAA6B,uDAAuD;AACpF;AACA;AACA;AACA;AACA,uBAAuB,sBAAsB;AAC7C;AACA;AACA,CAAC;AACD,gBAAgB,SAAI,IAAI,SAAI;AAC5B;AACA,gDAAgD,OAAO;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,mBAAO,CAAC,gDAAkB;AAC/C,SAAS,mBAAO,CAAC,qCAAU;AACiB;AACU;AACK;AACK;AACmC;AACV;AACzF;AACA;AACA;AACA,gDAAgD,yCAAyC;AACzF,2DAA2D,EAAE,6EAAoB;AACjF;AACA;AACA;AACA;AACA;AACA,yCAAyC,oEAAmB;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,EAAE,6EAAoB;AACnE;AACA;AACA;AACA,iDAAiD;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE,gEAAuB,4BAA4B,gEAAuB;AACjJ;AACA;AACA;AACA,YAAY,mEAAc;AAC1B;AACA,oBAAoB,8DAAS;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,wEAAuB;AACrE;AACA,wBAAwB,+EAAyB;AACjD;AACA,sDAAsD;AACtD;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA,8CAA8C,wEAAuB;AACrE;AACA,wBAAwB,iFAA2B;AACnD;AACA,sDAAsD;AACtD;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb,SAAS;AACT;AACA,sCAAsC,wCAAwC,EAAE;AAChF;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,0BAA0B,gDAAK;AAC/B,QAAQ,iDAAM;AACd;AACA;AACA;AACA,CAAC,CAAC,iEAAY;AACO;;;;;;;;;;;;;ACjKrB;AAAA;AAAA;AAAA;AAAA;AAAA;AACqD;AACH;AAClD;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,cAAc;AACvD;AACA,iDAAiD;AACjD,OAAO,6DAAc;AACrB,OAAO,6DAAc;AACrB,OAAO,6DAAc;AACrB;AACA;AACA,4BAA4B;AAC5B;AACA;AACA,IAAI,6DAAc;AAClB,IAAI,6DAAc;AAClB,IAAI,6DAAc;AAClB,IAAI,6DAAc;AAClB,IAAI,6DAAc;AAClB,IAAI,6DAAc;AAClB,IAAI,6DAAc;AAClB,IAAI,6DAAc;AAClB,IAAI,6DAAc;AAClB,IAAI,6DAAc;AAClB,IAAI,6DAAc;AAClB,IAAI,6DAAc;AAClB,IAAI,6DAAc;AAClB,wBAAwB,wBAAwB,EAAE;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,wCAAwC;AAC5E;AACA,kBAAkB;AAClB;AACA;AACA;AACA;AACA,WAAW,8DAAS;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,8DAAS;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,8DAAS;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD;AACpD;AACA;AACA,SAAS;AACT;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACO;AACP;AACA,IAAI,6DAAQ;AACZ;AACA,YAAY,8DAAS;AACrB;AACA;AACA;AACA,6DAA6D,2BAA2B,EAAE;AAC1F;AACA;AACA,yEAAyE,+CAA+C,EAAE;AAC1H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACO;AACP;AACA,IAAI,6DAAQ;AACZ;AACA,YAAY,8DAAS;AACrB;AACA;AACA;AACA,yEAAyE,+CAA+C,EAAE;AAC1H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACrPA;AAAA;AAAA;AAAA;AAAA;AAA4B;AAC5B;AACA,uDAAuD;AAChD,gBAAgB,mBAAO,CAAC,qCAAU;;;;;;;;;;;;;ACHzC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA,uBAAuB,mBAAO,CAAC,gDAAkB;AACR;AACiB;AACX;AACA;AAC/C;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B;AAC/B,WAAW,8DAAW;AACtB;AACA;AACA,CAAC;AACD,SAAS,8DAAW;AACpB;AACA;AACA;AACA,CAAC;AACD,WAAW,8DAAW;AACtB;AACA;AACA;AACA,CAAC;AACD,cAAc,8DAAW;AACzB;AACA,eAAe;AACf;AACA,CAAC;AACD;AACA;AACA;AACA,wBAAwB,8DAAW;AACnC;AACA;AACA,qCAAqC,iBAAiB;AACtD;AACA,oCAAoC;AACpC;AACA;AACA;AACA;AACA,sCAAsC,gDAAgD;AACtF,mCAAmC;AACnC;AACA;AACA,wCAAwC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uEAAsB;AACrC,KAAK;AACL;AACA;AACA,CAAC;AACD;AACA;AACA;AACA,mBAAmB,8DAAW;AAC9B;AACA,kBAAkB;AAClB;AACA,CAAC;AACD,6CAA6C,4DAAc;AACpD;AACP,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA,kCAAkC,4DAAc;AAChD;AACA,YAAY,4DAAc;AAC1B,YAAY,4DAAc;AAC1B;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,IAAI,4DAAc;AAClB;AACA;AACA;AACA;;;;;;;;;;;;;ACvGA;AAAA;AAAA;AAAA;AAAA;AAAA,iBAAiB,SAAI,IAAI,SAAI;AAC7B;AACA;AACA,cAAc,gBAAgB,sCAAsC,iBAAiB,EAAE;AACvF,6BAA6B,uDAAuD;AACpF;AACA;AACA;AACA;AACA,uBAAuB,sBAAsB;AAC7C;AACA;AACA,CAAC;AACiE;AAClE;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,+CAA+C,uBAAuB;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,2BAA2B;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD,iCAAiC;AACzF,mDAAmD,4BAA4B;AAC/E;AACA;AACA;AACA;AACA,qCAAqC,6EAAkB;AACvD;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP,wEAAwE,2CAA2C,EAAE;AACrH;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC7IA;AAAA;AAAA,gBAAgB,SAAI,IAAI,SAAI;AAC5B;AACA,gDAAgD,OAAO;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,uBAAuB,yBAAyB;AAChD,CAAC,IAAI","file":"millan.srs.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine(\"srs\", [], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"srs\"] = factory();\n\telse\n\t\troot[\"millan\"] = root[\"millan\"] || {}, root[\"millan\"][\"srs\"] = factory();\n})((typeof self !== 'undefined' ? self : this), function() {\nreturn "," \t// install a JSONP callback for chunk loading\n \tfunction webpackJsonpCallback(data) {\n \t\tvar chunkIds = data[0];\n \t\tvar moreModules = data[1];\n \t\tvar executeModules = data[2];\n\n \t\t// add \"moreModules\" to the modules object,\n \t\t// then flag all \"chunkIds\" as loaded and fire callback\n \t\tvar moduleId, chunkId, i = 0, resolves = [];\n \t\tfor(;i < chunkIds.length; i++) {\n \t\t\tchunkId = chunkIds[i];\n \t\t\tif(installedChunks[chunkId]) {\n \t\t\t\tresolves.push(installedChunks[chunkId][0]);\n \t\t\t}\n \t\t\tinstalledChunks[chunkId] = 0;\n \t\t}\n \t\tfor(moduleId in moreModules) {\n \t\t\tif(Object.prototype.hasOwnProperty.call(moreModules, moduleId)) {\n \t\t\t\tmodules[moduleId] = moreModules[moduleId];\n \t\t\t}\n \t\t}\n \t\tif(parentJsonpFunction) parentJsonpFunction(data);\n\n \t\twhile(resolves.length) {\n \t\t\tresolves.shift()();\n \t\t}\n\n \t\t// add entry modules from loaded chunk to deferred list\n \t\tdeferredModules.push.apply(deferredModules, executeModules || []);\n\n \t\t// run deferred modules when all chunks ready\n \t\treturn checkDeferredModules();\n \t};\n \tfunction checkDeferredModules() {\n \t\tvar result;\n \t\tfor(var i = 0; i < deferredModules.length; i++) {\n \t\t\tvar deferredModule = deferredModules[i];\n \t\t\tvar fulfilled = true;\n \t\t\tfor(var j = 1; j < deferredModule.length; j++) {\n \t\t\t\tvar depId = deferredModule[j];\n \t\t\t\tif(installedChunks[depId] !== 0) fulfilled = false;\n \t\t\t}\n \t\t\tif(fulfilled) {\n \t\t\t\tdeferredModules.splice(i--, 1);\n \t\t\t\tresult = __webpack_require__(__webpack_require__.s = deferredModule[0]);\n \t\t\t}\n \t\t}\n \t\treturn result;\n \t}\n\n \t// The module cache\n \tvar installedModules = {};\n\n \t// object to store loaded and loading chunks\n \t// undefined = chunk not loaded, null = chunk preloaded/prefetched\n \t// Promise = chunk loading, 0 = chunk loaded\n \tvar installedChunks = {\n \t\t\"srs\": 0\n \t};\n\n \tvar deferredModules = [];\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n \tvar jsonpArray = (typeof self !== 'undefined' ? self : this)[\"webpackJsonp\"] = (typeof self !== 'undefined' ? self : this)[\"webpackJsonp\"] || [];\n \tvar oldJsonpFunction = jsonpArray.push.bind(jsonpArray);\n \tjsonpArray.push = webpackJsonpCallback;\n \tjsonpArray = jsonpArray.slice();\n \tfor(var i = 0; i < jsonpArray.length; i++) webpackJsonpCallback(jsonpArray[i]);\n \tvar parentJsonpFunction = oldJsonpFunction;\n\n\n \t// add entry module to deferred list\n \tdeferredModules.push([\"./src/srs/index.ts\",\"vendors~graphql~shacl~sms~sparql~srs~turtle\",\"graphql~shacl~sms~sparql~srs~turtle\",\"graphql~sparql~srs\",\"shacl~srs~turtle\"]);\n \t// run deferred modules when ready\n \treturn checkDeferredModules();\n","var __assign = (this && this.__assign) || function () {\n    __assign = Object.assign || function(t) {\n        for (var s, i = 1, n = arguments.length; i < n; i++) {\n            s = arguments[i];\n            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p))\n                t[p] = s[p];\n        }\n        return t;\n    };\n    return __assign.apply(this, arguments);\n};\nexport var traverse = function (root, visit) {\n    _traverse(root, null, visit);\n};\nexport var unsafeTraverse = function (root, visit) {\n    _traverse(root, null, visit, false);\n};\nexport function isCstNode(object) {\n    return Boolean(object && 'name' in object);\n}\nvar TraverseContext = /** @class */ (function () {\n    function TraverseContext(_a) {\n        var node = _a.node, parentCtx = _a.parentCtx;\n        this.node = __assign({}, node);\n        this.parentCtx = __assign({}, parentCtx);\n    }\n    return TraverseContext;\n}());\nvar _traverse = function (root, ctx, visit, visitSafely) {\n    if (ctx === void 0) { ctx = new TraverseContext({ node: root }); }\n    if (visitSafely === void 0) { visitSafely = true; }\n    if (!isCstNode(root)) {\n        // must be a token\n        return visit(visitSafely ? __assign({}, ctx) : ctx);\n    }\n    // is a grammar rule node\n    var children = root.children;\n    Object.keys(children).forEach(function (key) {\n        var childType = children[key];\n        if (!childType.length) {\n            return;\n        }\n        childType.forEach(function (child) {\n            var childCtx = visitSafely\n                ? new TraverseContext({ node: child, parentCtx: ctx })\n                : { node: child, parentCtx: ctx };\n            var afterVisit = function (transformedCtx) {\n                var nextCtx = childCtx;\n                if (transformedCtx) {\n                    nextCtx = visitSafely\n                        ? new TraverseContext({\n                            node: transformedCtx.node,\n                            parentCtx: transformedCtx.parentCtx,\n                        })\n                        : {\n                            node: transformedCtx.node,\n                            parentCtx: transformedCtx.parentCtx,\n                        };\n                }\n                _traverse(child, nextCtx, visit, visitSafely);\n            };\n            visit(childCtx, afterVisit);\n        });\n    });\n};\n","var __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar baseTokens = require('./tokens').baseTokens;\nimport { BaseSparqlParser } from './BaseSparqlParser';\nimport { Parser } from 'chevrotain';\nvar W3SpecSparqlParser = /** @class */ (function (_super) {\n    __extends(W3SpecSparqlParser, _super);\n    function W3SpecSparqlParser(options) {\n        var _this = _super.call(this, options, baseTokens) || this;\n        Parser.performSelfAnalysis(_this);\n        return _this;\n    }\n    return W3SpecSparqlParser;\n}(BaseSparqlParser));\nexport { W3SpecSparqlParser };\n","var __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __assign = (this && this.__assign) || function () {\n    __assign = Object.assign || function(t) {\n        for (var s, i = 1, n = arguments.length; i < n; i++) {\n            s = arguments[i];\n            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p))\n                t[p] = s[p];\n        }\n        return t;\n    };\n    return __assign.apply(this, arguments);\n};\n// tslint:disable:function-name\nvar sparqlTokenMap = require('../sparql/tokens').sparqlTokenMap;\nvar _a = require('./tokens'), srsTokenMap = _a.srsTokenMap, srsTokenTypes = _a.srsTokenTypes, multiModeLexerDefinition = _a.multiModeLexerDefinition;\nimport { Parser, Lexer, } from 'chevrotain';\nimport { TurtleParser } from '../turtle/TurtleParser';\nimport { isCstNode, unsafeTraverse } from '../helpers/cst';\nimport { defaultNamespacesMap } from 'turtle/defaultNamespaces';\nimport { getSparqlSrsVisitor, reduceVisitorItemErrors, findAndSwapPlaceholders, } from './visitor';\nimport { addThenClauseErrorsToErrors, addIfClauseErrorsToErrors, } from './customErrors';\nvar SrsParser = /** @class */ (function (_super) {\n    __extends(SrsParser, _super);\n    function SrsParser(config) {\n        var _this = _super.call(this, __assign({ outputCst: true, recoveryEnabled: true }, config), srsTokenTypes, multiModeLexerDefinition, false) || this;\n        _this.baseNamespacesMap = Object.freeze(__assign({}, defaultNamespacesMap));\n        _this.namespacesMap = {};\n        _this.visitCst = function (cst) {\n            // To save resources while parsing, the sparqlSrsVisitor is a singleton.\n            if (!_this.sparqlSrsVisitor) {\n                var BaseSrsVisitor = _this.getBaseCstVisitorConstructorWithDefaults();\n                _this.sparqlSrsVisitor = getSparqlSrsVisitor(BaseSrsVisitor);\n            }\n            else {\n                _this.sparqlSrsVisitor.$resetState();\n            }\n            _this.sparqlSrsVisitor.visit(cst, _this.input);\n        };\n        _this.getSparqlRulesFromVisitor = function (cst) {\n            _this.visitCst(cst);\n            return {\n                groupGraphPatterns: _this.sparqlSrsVisitor.$getGroupGraphPatterns(),\n                triplesBlocks: _this.sparqlSrsVisitor.$getTriplesBlocks(),\n            };\n        };\n        _this.resetManagedState = function () {\n            _this.namespacesMap = __assign({}, defaultNamespacesMap);\n            _this.semanticErrors = [];\n        };\n        _this.setBaseNamespaces = function (newBaseNamespaces) {\n            _this.baseNamespacesMap = __assign({}, newBaseNamespaces);\n        };\n        _this.tokenize = function (document) {\n            return _this.lexer.tokenize(document).tokens;\n        };\n        _this.parse = function (document) {\n            _this.resetManagedState();\n            _this.input = _this.lexer.tokenize(document).tokens;\n            var cst = _this.SrsDoc();\n            var _a = _this.getSparqlRulesFromVisitor(cst), groupGraphPatterns = _a.groupGraphPatterns, triplesBlocks = _a.triplesBlocks;\n            // Pull visitor errors\n            var errors = _this.errors.concat(groupGraphPatterns.reduce(reduceVisitorItemErrors, []), triplesBlocks.reduce(reduceVisitorItemErrors, []));\n            var semanticErrors = _this.semanticErrors.slice();\n            // Replace placeholder CST nodes created by the SRS parser with CST nodes\n            // returned by the visitor sub-parsers.\n            unsafeTraverse(cst, function (ctx, next) {\n                var node = ctx.node, parentCtx = ctx.parentCtx;\n                if (isCstNode(node)) {\n                    return next();\n                }\n                var currentTokenName = node.tokenType.tokenName;\n                if (currentTokenName !== 'GroupGraphPattern' &&\n                    currentTokenName !== 'TriplesBlock') {\n                    return;\n                }\n                var parentNode = parentCtx.node;\n                // The SRS parser parses only Turtle and SRS-specific content (RULE, IF,\n                // THEN), and creates placeholder tokens for the blocks where SPARQL is\n                // valid. The SparqlSrsVisitor visits these nodes and delegates their\n                // parsing to a SPARQL parser. Here, we replace the placeholder nodes\n                // (`GroupGraphPattern` and `TriplesBlock`) with the real ones from the\n                // SPARQL parser, collecting some custom SRS-specific errors along the\n                // way.\n                if (parentNode.name === 'IfClause') {\n                    var matchingVisitorItem = findAndSwapPlaceholders(node, parentNode, groupGraphPatterns, 'GroupGraphPattern');\n                    if (matchingVisitorItem) {\n                        addIfClauseErrorsToErrors({\n                            fullCtx: ctx,\n                            namespacesMap: __assign({}, _this.baseNamespacesMap, _this.namespacesMap),\n                            cst: matchingVisitorItem.parseResult.cst,\n                            errors: errors,\n                            semanticErrors: semanticErrors,\n                        });\n                    }\n                }\n                else if (parentNode.name === 'ThenClause') {\n                    var matchingVisitorItem = findAndSwapPlaceholders(node, parentNode, triplesBlocks, 'TriplesBlock');\n                    if (matchingVisitorItem) {\n                        addThenClauseErrorsToErrors({\n                            fullCtx: ctx,\n                            namespacesMap: __assign({}, _this.baseNamespacesMap, _this.namespacesMap),\n                            cst: matchingVisitorItem.parseResult.cst,\n                            errors: errors,\n                            semanticErrors: semanticErrors,\n                        });\n                    }\n                }\n            });\n            return {\n                semanticErrors: semanticErrors,\n                errors: errors,\n                cst: cst,\n            };\n        };\n        _this.SrsDoc = _this.RULE('SrsDoc', function () {\n            _this.SUBRULE(_this.turtleDoc);\n            _this.MANY(function () {\n                _this.SUBRULE(_this.RuleDoc);\n                _this.MANY1(function () {\n                    _this.SUBRULE(_this.triples);\n                    _this.CONSUME(sparqlTokenMap.Period);\n                });\n            });\n        });\n        _this.RuleDoc = _this.RULE('RuleDoc', function () {\n            _this.OPTION(function () { return _this.SUBRULE(_this.RuleClause); });\n            _this.SUBRULE(_this.IfClause);\n            _this.SUBRULE(_this.ThenClause);\n        });\n        _this.RuleClause = _this.RULE('RuleClause', function () {\n            _this.CONSUME(srsTokenMap.Rule);\n            _this.SUBRULE(_this.iri);\n        });\n        _this.IfClause = _this.RULE('IfClause', function () {\n            _this.CONSUME(srsTokenMap.If);\n            _this.CONSUME(srsTokenMap.GroupGraphPattern);\n        });\n        _this.ThenClause = _this.RULE('ThenClause', function () {\n            _this.CONSUME(srsTokenMap.Then);\n            _this.CONSUME(sparqlTokenMap.LCurly);\n            _this.CONSUME(srsTokenMap.TriplesBlock);\n            _this.CONSUME(srsTokenMap.EndThen);\n        });\n        _this.lexer = new Lexer(multiModeLexerDefinition);\n        Parser.performSelfAnalysis(_this);\n        return _this;\n    }\n    return SrsParser;\n}(TurtleParser));\nexport { SrsParser };\n","var _a;\nimport { isCstNode, traverse } from '../helpers/cst';\nimport { sparqlTokenMap } from '../sparql/tokens';\n// RegEx for matching any relevant children of `Expression` inside of `Bind`;\n// used to avoid false negatives in the check for disallowed literals inside of\n// `Bind`.\nvar subExpressionMatcher = /(?:[A-Z]+Expression|ValueLogical)$/i;\n// Default: just don't abort early at all. Used in the stack unwinding process\n// that creates an error rule stack.\nvar defaultEarlyAbortTest = function () { return false; };\n// Tokens that are allowed in SPARQL but not inside the `IfClause` of SRS.\nvar disallowedSparqlTokenNameToRuleMap = (_a = {},\n    _a[sparqlTokenMap.EXISTS.tokenName] = 'ExistsFunction',\n    _a[sparqlTokenMap.NOT_EXISTS.tokenName] = 'NotExistsFunction',\n    _a[sparqlTokenMap.NOW.tokenName] = 'BuiltInCall_NOW',\n    _a);\nvar disallowedSparqlTokenNames = Object.keys(disallowedSparqlTokenNameToRuleMap);\n// Token names for literals; these are not allowed in the subject position of\n// certain patterns in SRS.\nvar disallowedSparqlLiteralTokenNames = [\n    sparqlTokenMap.DOUBLE,\n    sparqlTokenMap.DECIMAL,\n    sparqlTokenMap.INTEGER,\n    sparqlTokenMap.DOUBLE_POSITIVE,\n    sparqlTokenMap.DECIMAL_POSITIVE,\n    sparqlTokenMap.INTEGER_POSITIVE,\n    sparqlTokenMap.DOUBLE_NEGATIVE,\n    sparqlTokenMap.DECIMAL_NEGATIVE,\n    sparqlTokenMap.INTEGER_NEGATIVE,\n    sparqlTokenMap.STRING_LITERAL1,\n    sparqlTokenMap.STRING_LITERAL2,\n    sparqlTokenMap.STRING_LITERAL_LONG1,\n    sparqlTokenMap.STRING_LITERAL_LONG2,\n].map(function (token) { return token.tokenName; });\n// Walks back up the tree to construct the rule stack, first going upward\n// through the provided `traverseCtx`, and then continuing up through the\n// `fullCtx`. `traverseCtx` is intended to be the \"inner\" ITraverseContext\n// representing the results of the SPARQL sub-parser used by the\n// SparqlSrsVisitor. `fullCtx` is intended to be the \"outer\" ITraverseContext\n// representing the results of the SRS parser itself. The SRS parser delegates\n// blocks of SPARQL to a SPARQL sub-parser, so, by combinging the two contexts,\n// we get the full parser stack. The traversal adds rules to the stack only\n// once a rule matching one of the `startRuleNames` is hit.\n//\n// At the point where the traversal of `traverseCtx` ends and the traversal of\n// `fullCtx` begins, you may need to insert a rule into the stack (e.g.,\n// because the `traverseCtx` doesn't include the top-level rule for that\n// parse). If so, use `topLevelSubParserRuleName`.\n//\n// In some cases, there is a need to track nodes and potentially bail out early\n// at certain points while constructing the rule stack. For that, use\n// `earlyAbortTest`. If that method returns true, the rule stack construction\n// will abort.\nfunction getCustomErrorRuleStack(traverseCtx, fullCtx, startRuleNames, topLevelSubParserRuleName, earlyAbortTest) {\n    if (earlyAbortTest === void 0) { earlyAbortTest = defaultEarlyAbortTest; }\n    if (!traverseCtx) {\n        return []; // forced early exit\n    }\n    var ruleStack = [];\n    var stackUnwindingPointer = traverseCtx;\n    // Move up from current context to the first rule that should \"start\" the stack.\n    while (isCstNode(stackUnwindingPointer.node) &&\n        !startRuleNames.includes(stackUnwindingPointer.node.name)) {\n        if (earlyAbortTest(stackUnwindingPointer)) {\n            return [];\n        }\n        stackUnwindingPointer = stackUnwindingPointer.parentCtx;\n    }\n    // Now start adding all found rules to the stack as we move upward.\n    while (isCstNode(stackUnwindingPointer.node)) {\n        ruleStack.unshift(stackUnwindingPointer.node.name);\n        if (earlyAbortTest(stackUnwindingPointer)) {\n            return [];\n        }\n        stackUnwindingPointer = stackUnwindingPointer.parentCtx;\n    }\n    // If the rule stack of the sub-parser doesn't get all the way up to the\n    // relevant top-level rule, this will force the top-level rule to be put onto\n    // the stack before proceeding.\n    if (typeof topLevelSubParserRuleName === 'string') {\n        ruleStack.unshift(topLevelSubParserRuleName);\n    }\n    // Now that we've got the sub-parser's rule stack, we trace the remaining\n    // outer parser's stack to get to the true bottom of the stack.\n    stackUnwindingPointer = fullCtx;\n    while (stackUnwindingPointer) {\n        if (isCstNode(stackUnwindingPointer.node)) {\n            ruleStack.unshift(stackUnwindingPointer.node.name);\n            if (earlyAbortTest(stackUnwindingPointer)) {\n                return [];\n            }\n        }\n        stackUnwindingPointer = stackUnwindingPointer.parentCtx;\n    }\n    return ['SrsDoc'].concat(ruleStack);\n}\nvar getCustomIRecognitionException = function (_a) {\n    var name = _a.name, message = _a.message, node = _a.node, ruleStack = _a.ruleStack;\n    return ({\n        name: name,\n        message: message,\n        token: node,\n        context: {\n            ruleStack: ruleStack,\n            // `ruleOccurrenceStack` is meaningless to us as it just\n            // records the number used when the chevrotain rule is\n            // created (e.g., SUBRULE1 vs SUBRULE2); we can't know that\n            // or care about that here\n            ruleOccurrenceStack: [],\n        },\n        resyncedTokens: [],\n    });\n};\nvar getNoPrefixError = function (node, parentCtx, fullCtx, subParserRuleName) {\n    return getCustomIRecognitionException({\n        name: 'NoNamespacePrefixError',\n        message: \"A prefix (\\\"\" + node.image + \"\\\") was used for which there was no namespace defined.\",\n        node: node,\n        ruleStack: getCustomErrorRuleStack(parentCtx, fullCtx, ['PrefixedName'], subParserRuleName),\n    });\n};\nvar getDisallowedTokenError = function (node, parentCtx, fullCtx) {\n    return getCustomIRecognitionException({\n        name: 'DisallowedTokenError',\n        message: \"Token \" + node.tokenType.tokenName + \" cannot be used in Stardog Rules.\",\n        node: node,\n        ruleStack: getCustomErrorRuleStack(parentCtx, fullCtx, [disallowedSparqlTokenNameToRuleMap[node.tokenType.tokenName]], 'GroupGraphPattern'),\n    });\n};\nvar getDisallowedLiteralError = function (node, parentCtx, fullCtx, subParserRuleName) {\n    var foundPropertyListPathNotEmptyCtx = null;\n    var didFindSubExpressionWithMultipleChildren = false;\n    var errorContext = null;\n    var errorRuleStack = getCustomErrorRuleStack(parentCtx, fullCtx, ['Expression', 'TriplesSameSubjectPath'], subParserRuleName, function (stackCtx) {\n        var node = stackCtx.node, parentCtx = stackCtx.parentCtx;\n        var nodeName = node.name;\n        if (nodeName === 'PropertyListPathNotEmpty') {\n            // Track the found `PropertyListPathNotEmmpty` node and keep going.\n            foundPropertyListPathNotEmptyCtx = stackCtx;\n            return false;\n        }\n        if (!didFindSubExpressionWithMultipleChildren &&\n            subExpressionMatcher.test(nodeName)) {\n            // Track that we found a sub-expression with multiple children, then\n            // keep going.\n            didFindSubExpressionWithMultipleChildren =\n                parentCtx.node.children[nodeName].length > 1;\n            return false;\n        }\n        var isExpression = nodeName === 'Expression';\n        var isTriplesBlock = nodeName === 'TriplesSameSubjectPath';\n        if (!isExpression && !isTriplesBlock) {\n            return false;\n        }\n        var isBoundExpressionWithLiteralSubject = isExpression &&\n            parentCtx.node.name === 'Bind' &&\n            // If we've found a sub-expression with multiple children, it's highly\n            // likely (maybe definite?) that this `Bind` does not include an invalid\n            // literal as a subject, so we don't count this as an error. This _may_\n            // allow rare false positives, but it definitely prevents false\n            // negatives of the sort described in https://github.com/stardog-union/millan/issues/22\n            !didFindSubExpressionWithMultipleChildren;\n        var isTriplesBlockSubject = isTriplesBlock &&\n            (!foundPropertyListPathNotEmptyCtx ||\n                foundPropertyListPathNotEmptyCtx.parentCtx.node.name !==\n                    'TriplesSameSubjectPath');\n        if (isBoundExpressionWithLiteralSubject || isTriplesBlockSubject) {\n            errorContext = isBoundExpressionWithLiteralSubject\n                ? 'Bind'\n                : 'TriplesBlock';\n            return false;\n        }\n        // We got to the Expression or TriplesBlock containing the literal, but\n        // the literal wasn't in the subject position (i.e., was not the lead\n        // Expression inside of Bind and was not the subject of\n        // TriplesSameSubjectPath), so we can bail early here.\n        return true;\n    });\n    if (errorRuleStack.length === 0) {\n        return;\n    }\n    return getCustomIRecognitionException({\n        name: 'DisallowedLiteralError',\n        message: \"Token \" + node.tokenType.tokenName + \" (\" + node.image + \") cannot be used as a subject inside of a \" + errorContext + \" in Stardog Rules Syntax.\",\n        node: node,\n        ruleStack: errorRuleStack,\n    });\n};\n// Since the SRS parser delegates to the SPARQL parser inside of\n// an SRS `IfClause`, and SPARQL allows certain constructs that SRS does not,\n// we need to create our own errors for SRS-specific restrictions here.\nexport function addIfClauseErrorsToErrors(_a) {\n    var cst = _a.cst, namespacesMap = _a.namespacesMap, fullCtx = _a.fullCtx, errors = _a.errors, semanticErrors = _a.semanticErrors;\n    traverse(cst, function (ctx, next) {\n        var node = ctx.node, parentCtx = ctx.parentCtx;\n        if (isCstNode(node)) {\n            return next();\n        }\n        var tokenName = node.tokenType.tokenName;\n        if (disallowedSparqlTokenNames.some(function (name) { return name === tokenName; })) {\n            errors.push(getDisallowedTokenError(node, parentCtx, fullCtx));\n        }\n        if (disallowedSparqlLiteralTokenNames.some(function (tokenName) { return tokenName === node.tokenType.tokenName; })) {\n            var error = getDisallowedLiteralError(node, parentCtx, fullCtx, 'GroupGraphPattern');\n            if (error) {\n                errors.push(error);\n            }\n        }\n        if (tokenName === 'PNAME_NS' || tokenName === 'PNAME_LN') {\n            var prefix = node.image.split(':').shift();\n            if (!namespacesMap[prefix]) {\n                semanticErrors.push(getNoPrefixError(node, parentCtx, fullCtx, 'GroupGraphPattern'));\n            }\n        }\n    });\n    return {\n        errors: errors,\n        semanticErrors: semanticErrors,\n    };\n}\nexport function addThenClauseErrorsToErrors(_a) {\n    var cst = _a.cst, namespacesMap = _a.namespacesMap, errors = _a.errors, semanticErrors = _a.semanticErrors, fullCtx = _a.fullCtx;\n    traverse(cst, function (ctx, next) {\n        var node = ctx.node, parentCtx = ctx.parentCtx;\n        if (isCstNode(node)) {\n            return next();\n        }\n        var tokenName = node.tokenType.tokenName;\n        if (disallowedSparqlLiteralTokenNames.some(function (tokenName) { return tokenName === node.tokenType.tokenName; })) {\n            var error = getDisallowedLiteralError(node, parentCtx, fullCtx, 'GroupGraphPattern');\n            if (error) {\n                errors.push(error);\n            }\n        }\n        if (tokenName === 'PNAME_NS' || tokenName === 'PNAME_LN') {\n            var prefix = node.image.split(':').shift();\n            if (!namespacesMap[prefix]) {\n                semanticErrors.push(getNoPrefixError(node, parentCtx, fullCtx, 'TriplesBlock'));\n            }\n        }\n    });\n    return {\n        errors: errors,\n        semanticErrors: semanticErrors,\n    };\n}\n","export * from './SrsParser';\n// Convenience imports/exports that aren't core functionality:\n// NOTE: Tokens MUST be imported using CommonJS syntax; see here: https://github.com/SAP/chevrotain/issues/345\nexport var srsTokens = require('./tokens');\n","var _a;\nvar turtleTokenTypes = require('../turtle/tokens').turtleTokenTypes;\nimport { createToken } from 'chevrotain';\nimport { CATCH_ALL_AT_LEAST_ONE } from 'helpers/matchers';\nimport { turtleTokenMap } from 'turtle/tokens';\nimport { sparqlTokenMap } from 'sparql/tokens';\nvar LexerMode;\n(function (LexerMode) {\n    LexerMode[\"TURTLE\"] = \"turtle\";\n    LexerMode[\"IFCLAUSE\"] = \"ifclause\";\n    LexerMode[\"THENCLAUSE\"] = \"thenclause\";\n})(LexerMode || (LexerMode = {}));\nvar Rule = createToken({\n    name: 'Rule',\n    pattern: /rule/i,\n});\nvar If = createToken({\n    name: 'If',\n    pattern: /if/i,\n    push_mode: LexerMode.IFCLAUSE,\n});\nvar Then = createToken({\n    name: 'Then',\n    pattern: /then/i,\n    push_mode: LexerMode.THENCLAUSE,\n});\nvar EndThen = createToken({\n    name: 'EndThen',\n    pattern: '}',\n    pop_mode: true,\n});\n// NOTE: Not a SPARQL GroupGraphPattern. Rather, a placeholder for one. We have\n// to let the SRS parser create this token, then replace with a token returned\n// by the SPARQL sub-parser.\nvar GroupGraphPattern = createToken({\n    name: 'GroupGraphPattern',\n    pattern: function (text, startOffset) {\n        if (startOffset === void 0) { startOffset = 0; }\n        // Capture a single brace and then anything up to its closing brace.\n        if (text[startOffset] !== '{') {\n            return null;\n        }\n        var unclosedBraceCount = 1;\n        var cursor;\n        for (cursor = startOffset + 1; cursor < text.length && unclosedBraceCount > 0; cursor++) {\n            if (text[cursor] === '{') {\n                unclosedBraceCount++;\n            }\n            else if (text[cursor] === '}') {\n                unclosedBraceCount--;\n            }\n        }\n        if (unclosedBraceCount > 0) {\n            return null;\n        }\n        return CATCH_ALL_AT_LEAST_ONE.exec(text.slice(startOffset, cursor));\n    },\n    line_breaks: true,\n    pop_mode: true,\n});\n// NOTE: Not a SPARQL TriplesBlock. Rather, a placeholder for one. We have\n// to let the SRS parser create this token, then replace with a token returned\n// by the SPARQL sub-parser.\nvar TriplesBlock = createToken({\n    name: 'TriplesBlock',\n    pattern: /[^{}]+/,\n    line_breaks: true,\n});\nvar indexOfIriRef = turtleTokenTypes.indexOf(turtleTokenMap.IRIREF);\nexport var multiModeLexerDefinition = {\n    modes: (_a = {},\n        _a[LexerMode.TURTLE] = turtleTokenTypes.slice(0, indexOfIriRef + 1).concat([\n            Rule,\n            If,\n            Then\n        ], turtleTokenTypes.slice(indexOfIriRef + 1)),\n        _a[LexerMode.IFCLAUSE] = [turtleTokenMap.WhiteSpace, GroupGraphPattern],\n        _a[LexerMode.THENCLAUSE] = [\n            turtleTokenMap.WhiteSpace,\n            sparqlTokenMap.LCurly,\n            EndThen,\n            TriplesBlock,\n        ],\n        _a),\n    defaultMode: LexerMode.TURTLE,\n};\nexport var srsTokenMap = {\n    Rule: Rule,\n    If: If,\n    Then: Then,\n    EndThen: EndThen,\n    GroupGraphPattern: GroupGraphPattern,\n    TriplesBlock: TriplesBlock,\n};\nexport var srsTokenTypes = [\n    Rule,\n    If,\n    Then,\n    EndThen,\n    sparqlTokenMap.LCurly\n].concat(turtleTokenTypes, [\n    GroupGraphPattern,\n    TriplesBlock,\n]);\n","var __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nimport { W3SpecSparqlParser } from '../sparql/W3SpecSparqlParser';\n// Returns a custom visitor that extends the BaseVisitor for the SRS parser.\n// When the visitor encounters an SRS `IfClause` or an SRS `ThenClause`, it\n// delegates parsing of the block to the existing SPARQL parser's relevant\n// sub-rule (GroupGraphPattern or TriplesBlock).\nexport var getSparqlSrsVisitor = function (BaseVisitor) {\n    var SparqlSrsVisitor = /** @class */ (function (_super) {\n        __extends(SparqlSrsVisitor, _super);\n        function SparqlSrsVisitor() {\n            var _this = _super.call(this) || this;\n            _this.groupGraphPatterns = [];\n            _this.triplesBlocks = [];\n            // Get and store the SPARQL `GroupGraphPattern` that should replace the\n            // SRS placeholder `GroupGraphPattern` token inside of an SRS `IfClause`.\n            _this.IfClause = function (ctx, cstInputTokens) {\n                var GroupGraphPattern = ctx.GroupGraphPattern;\n                _this.$storePlaceholderTokenReplacement({\n                    tokenStore: _this.groupGraphPatterns,\n                    originalTokenContext: GroupGraphPattern,\n                    subParserRule: _this.sparqlParser.parseGroupGraphPattern.bind(_this.sparqlParser),\n                    cstInputTokens: cstInputTokens,\n                });\n            };\n            // Get and store the SPARQL `TriplesBlock` that should replace the\n            // SRS placeholder `TriplesBlock` token inside of an SRS `ThenClause`.\n            _this.ThenClause = function (ctx, cstInputTokens) {\n                var TriplesBlock = ctx.TriplesBlock;\n                _this.$storePlaceholderTokenReplacement({\n                    tokenStore: _this.triplesBlocks,\n                    originalTokenContext: TriplesBlock,\n                    subParserRule: _this.sparqlParser.parseTriplesBlock.bind(_this.sparqlParser),\n                    cstInputTokens: cstInputTokens,\n                });\n            };\n            // Utility methods ('$' prefix is necessary to prevent chevrotain's\n            // `validateVisitor` method from complaining that these are not grammar\n            // rules):\n            _this.$storePlaceholderTokenReplacement = function (_a) {\n                var tokenStore = _a.tokenStore, _b = _a.originalTokenContext, originalTokenContext = _b === void 0 ? [] : _b, subParserRule = _a.subParserRule, cstInputTokens = _a.cstInputTokens, stripWrappers = _a.stripWrappers;\n                var originalToken = originalTokenContext[0];\n                if (!originalToken || typeof originalToken.image !== 'string') {\n                    return;\n                }\n                var replacement = _this.$getPlaceholderTokenReplacement(originalToken, subParserRule, cstInputTokens, stripWrappers);\n                tokenStore.push({\n                    parseResult: replacement,\n                    originalToken: originalToken,\n                });\n            };\n            _this.$getPlaceholderTokenReplacement = function (originalToken, subParserRule, cstInputTokens, stripWrappers) {\n                if (stripWrappers === void 0) { stripWrappers = false; }\n                // Because we are replacing tokens by delegating the parsing of parts\n                // of the original document to sub-parsers, we add some empty padding to\n                // the part that is passed to the sub-parser, where the amount of padding\n                // matches the start line and offset of the token we are replacing. This\n                // ensures that all tokens have the right positions in the resulting CST\n                // (otherwise, the sub-parsers assume that the text starts at offset 0).\n                var image = originalToken.image;\n                var frontPadding = '';\n                var latestEndOffset = 0;\n                var latestEndLine = 0;\n                // Traditional `for` loop because we need to `break`.\n                for (var i = 0; i < cstInputTokens.length; i++) {\n                    var token = cstInputTokens[i];\n                    if (i > 0) {\n                        // Account for whitespace between this token and the previous one.\n                        var linesBetweenTokens = token.startLine - latestEndLine;\n                        var untokenizedSpaceBetweenTokens = token.startOffset - 1 - latestEndOffset - linesBetweenTokens;\n                        if (linesBetweenTokens > 0) {\n                            frontPadding += '\\n'.repeat(linesBetweenTokens - 1);\n                            frontPadding +=\n                                ' '.repeat(Math.max(untokenizedSpaceBetweenTokens, 0)) + '\\n';\n                        }\n                        else {\n                            frontPadding += ' '.repeat(Math.max(untokenizedSpaceBetweenTokens, 0));\n                        }\n                    }\n                    if (token === originalToken) {\n                        break;\n                    }\n                    // We haven't hit the token we're replacing yet, so we need to continue\n                    // accumulating padding by adding the newlines _inside_ the current\n                    // token, and replacing all non-newline characters inside the current\n                    // token with spaces.\n                    var newlinesInToken = token.image.split('\\n');\n                    newlinesInToken.forEach(function (line, idx) {\n                        if (idx > 0) {\n                            frontPadding += '\\n';\n                        }\n                        frontPadding += ' '.repeat(line.length);\n                    });\n                    // Track where the current token ends, in case the next token starts\n                    // much later (meaning that there was untokenized stuff (e.g.,\n                    // whitespace) in between) that needs to be accounted for.\n                    latestEndOffset = token.endOffset;\n                    latestEndLine = token.endLine;\n                }\n                // Finally, if we're stripping the wrappers (e.g., braces), replace them\n                // with whitespace.\n                var parseImage = stripWrappers ? \" \" + image.slice(1, -1) + \" \" : image;\n                return subParserRule(\"\" + frontPadding + parseImage);\n            };\n            _this.$getGroupGraphPatterns = function () { return _this.groupGraphPatterns; };\n            _this.$getTriplesBlocks = function () { return _this.triplesBlocks; };\n            _this.$resetState = function () {\n                _this.groupGraphPatterns = [];\n                _this.triplesBlocks = [];\n            };\n            _this.sparqlParser = new W3SpecSparqlParser();\n            _this.validateVisitor();\n            return _this;\n        }\n        return SparqlSrsVisitor;\n    }(BaseVisitor));\n    return new SparqlSrsVisitor();\n};\nexport function reduceVisitorItemErrors(acc, item) {\n    return acc.concat(item.parseResult.errors);\n}\n// The SRS cst contains placeholder tokens for unparsed blocks of SPARQL\n// inside of an SRS `IfClause` or `ThenClause`. This method swaps out those\n// placeholders with the actual SPARQL CST created by the SparqlSrsVisitor.\nexport function findAndSwapPlaceholders(node, parentNode, visitorItems, key) {\n    var matchingVisitorItem = visitorItems.find(function (visitorItem) { return visitorItem.originalToken === node; });\n    if (matchingVisitorItem) {\n        parentNode.children[key] = [matchingVisitorItem.parseResult.cst];\n    }\n    return matchingVisitorItem;\n}\n","var __assign = (this && this.__assign) || function () {\n    __assign = Object.assign || function(t) {\n        for (var s, i = 1, n = arguments.length; i < n; i++) {\n            s = arguments[i];\n            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p))\n                t[p] = s[p];\n        }\n        return t;\n    };\n    return __assign.apply(this, arguments);\n};\nexport var defaultNamespacesMap = Object.freeze(['', 'rdf', 'rdfs', 'xsd', 'owl', 'stardog'].reduce(function (namespacesMap, prefix) {\n    var _a;\n    return (__assign({}, namespacesMap, (_a = {}, _a[prefix] = true, _a)));\n}, {}));\n"],"sourceRoot":""}